<p align="center">
    <a href="logo">
        <img src="pics/flash_attn.png" width="50%"/>
    </a>
</p>

<p align="center">
    <a href="License"><img src="https://img.shields.io/github/license/eljandoubi/triton-flash-attn"></a>
    <a href="Linux"><img src="https://img.shields.io/github/actions/workflow/status/eljandoubi/triton-flash-attn/main.yml?label=Linux"></a>
    <a href="Conda"><img src="https://img.shields.io/github/actions/workflow/status/eljandoubi/triton-flash-attn/main.yml?label=Conda"></a>
</p>

Coding Flash Attention from scratch using triton and pytorch.

## Setup environment
* Clone the repository and Go to `triton-flash-attn` directory.
```bash
git clone https://github.com/eljandoubi/triton-flash-attn.git && cd triton-flash-attn
```

* Build environment.
```bash
make build
```

## Clean environment
```bash
make clean
```
